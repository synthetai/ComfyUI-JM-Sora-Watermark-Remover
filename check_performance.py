#!/usr/bin/env python3
"""æ£€æŸ¥å½“å‰ç¯å¢ƒçš„æ¶æ„å’Œæ€§èƒ½"""
import platform
import sys
import torch

print("=== ç³»ç»Ÿå’ŒPythonæ¶æ„æ£€æŸ¥ ===\n")

# ç³»ç»Ÿæ¶æ„
print(f"ç³»ç»Ÿæ¶æ„: {platform.machine()}")
print(f"ç³»ç»Ÿç‰ˆæœ¬: {platform.platform()}")

# Pythonæ¶æ„
print(f"\nPythonç‰ˆæœ¬: {sys.version}")
print(f"Pythonè·¯å¾„: {sys.executable}")

# ä½¿ç”¨platformæ£€æµ‹
import subprocess
result = subprocess.run(['file', sys.executable], capture_output=True, text=True)
if 'arm64' in result.stdout:
    print("âœ… Pythonæ¶æ„: ARM64 (åŸç”Ÿ)")
elif 'x86_64' in result.stdout:
    print("âŒ Pythonæ¶æ„: Intel x86_64 (Rosetta 2è½¬è¯‘)")
    print("   âš ï¸  æ€§èƒ½æŸå¤±: ~20-30%")
    print("   âš ï¸  å»ºè®®å®‰è£…ARM64ç‰ˆæœ¬çš„Conda/Miniforge")
else:
    print(f"æœªçŸ¥æ¶æ„: {result.stdout}")

# PyTorchå’ŒMPS
print(f"\n=== PyTorché…ç½® ===\n")
print(f"PyTorchç‰ˆæœ¬: {torch.__version__}")
print(f"MPSå¯ç”¨: {torch.backends.mps.is_available()}")
print(f"MPSå·²æ„å»º: {torch.backends.mps.is_built()}")

# æ€§èƒ½æµ‹è¯•
if torch.backends.mps.is_available():
    print("\n=== MPSæ€§èƒ½æµ‹è¯• ===\n")
    try:
        import time
        # åˆ›å»ºæµ‹è¯•å¼ é‡
        size = 1000
        cpu_tensor = torch.randn(size, size)
        mps_tensor = cpu_tensor.to('mps')

        # CPUæµ‹è¯•
        start = time.time()
        for _ in range(10):
            _ = torch.matmul(cpu_tensor, cpu_tensor)
        cpu_time = time.time() - start

        # MPSæµ‹è¯•
        start = time.time()
        for _ in range(10):
            _ = torch.matmul(mps_tensor, mps_tensor)
        torch.mps.synchronize()  # ç­‰å¾…GPUå®Œæˆ
        mps_time = time.time() - start

        print(f"CPUæ—¶é—´: {cpu_time:.4f}ç§’")
        print(f"MPSæ—¶é—´: {mps_time:.4f}ç§’")
        print(f"åŠ é€Ÿæ¯”: {cpu_time/mps_time:.2f}x")

        if mps_time >= cpu_time:
            print("\nâš ï¸  è­¦å‘Šï¼šMPSæ²¡æœ‰æ¯”CPUå¿«ï¼Œå¯èƒ½å› ä¸ºè¿è¡Œåœ¨Rosetta 2ä¸‹")
            print("   å»ºè®®å®‰è£…ARM64åŸç”ŸPythonä»¥è·å¾—å®Œæ•´GPUåŠ é€Ÿ")
    except Exception as e:
        print(f"MPSæµ‹è¯•å¤±è´¥: {e}")
        print("è¿™å¯èƒ½æ˜¯å› ä¸ºè¿è¡Œåœ¨Intel Pythonä¸‹")

print("\n=== å»ºè®® ===\n")

result = subprocess.run(['file', sys.executable], capture_output=True, text=True)
if 'x86_64' in result.stdout:
    print("ğŸ”´ å½“å‰ä½¿ç”¨Intelç‰ˆæœ¬Pythonï¼ˆRosetta 2ï¼‰")
    print("\næ¨èæ“ä½œ:")
    print("1. å®‰è£…ARM64ç‰ˆæœ¬çš„Miniforge:")
    print("   curl -L -O https://github.com/conda-forge/miniforge/releases/latest/download/Miniforge3-MacOSX-arm64.sh")
    print("   bash Miniforge3-MacOSX-arm64.sh")
    print("\n2. æˆ–è€…ä½¿ç”¨detection_skipå‚æ•°ä¼˜åŒ–å½“å‰ç¯å¢ƒ:")
    print("   åœ¨ComfyUIä¸­è®¾ç½® detection_skip=5 å¯æå‡çº¦5å€é€Ÿåº¦")
else:
    print("âœ… å½“å‰ä½¿ç”¨ARM64åŸç”ŸPython")
    print("   æ€§èƒ½å·²ä¼˜åŒ–ï¼Œå¦‚æœè¿˜æ˜¯æ…¢ï¼Œæ£€æŸ¥LaMAæ˜¯å¦æ”¯æŒMPS")
